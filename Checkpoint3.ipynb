{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "np5vIrN6yHMC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets,transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veM3JbPyPrY2",
        "outputId": "bd9c60b8-1f80-4771-fac9-384410f39aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels input [0 1 2 3 4 5 6 7 8 9], Count [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
            "Unique labels after pruning [4 8], Count [  29 5851]\n",
            "Unique labels input [0 1 2 3 4 5 6 7 8 9], Count [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n",
            "Unique labels after pruning [4 8], Count [982 974]\n",
            "Unique labels input [0 1 2 3 4 5 6 7 8 9], Count [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n",
            "Unique labels after pruning [4 8], Count [982 974]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from higher import innerloop_ctx as metaloop\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  '''returns an imbalanced mnist dataset depending on class_ratios and noise_ratios that you enter '''\n",
        "    def __init__(self, X, y, class_ratios, noise_ratios):\n",
        "        self.X = np.copy(X)\n",
        "        self.y = np.copy(y)\n",
        "        N = len(X)\n",
        "\n",
        "        #  get unique labels and their count in the dataset\n",
        "        self.unique_y, self.y_counts = np.unique(self.y, return_counts=True)\n",
        "        assert len(class_ratios) == len(self.unique_y)\n",
        "        assert len(noise_ratios) == len(self.unique_y)\n",
        "        print(f\"Unique labels input {self.unique_y}, Count {self.y_counts}\")\n",
        "\n",
        "        # normalize class ratio list\n",
        "        self.class_ratios = class_ratios\n",
        "\n",
        "        # prune dataset\n",
        "        for label in self.unique_y:\n",
        "          idx = np.where(self.y == label)[0]\n",
        "          n_samples = min(len(idx),int(self.class_ratios[label] * len(idx)))\n",
        "          to_remove = np.random.choice(idx, len(idx) - n_samples, replace=False)\n",
        "          self.y[to_remove] = -10000\n",
        "        self.X = self.X[self.y!=-10000]\n",
        "        self.y = self.y[self.y!=-10000]\n",
        "\n",
        "        self.unique_y, self.y_counts = np.unique(self.y, return_counts=True)\n",
        "        print(f\"Unique labels after pruning {self.unique_y}, Count {self.y_counts}\")\n",
        "\n",
        "        # add noise to each class\n",
        "        self.noise_ratios = noise_ratios\n",
        "        for label in self.unique_y:\n",
        "          idx = np.where(self.y == label)[0]\n",
        "          n_noise = min(len(idx),int(self.noise_ratios[label] * N))\n",
        "          to_noise = np.random.choice(idx, n_noise, replace=False)\n",
        "          self.y[to_noise] = np.random.choice(self.unique_y, n_noise, replace=True)\n",
        "\n",
        "        self.N_classes = len(self.unique_y)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "        onehot_label = np.where(self.unique_y == label)[0][0]\n",
        "        onehot_label = torch.tensor(onehot_label, dtype=torch.float32)\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float32)/255.0\n",
        "        image = image.unsqueeze(0)\n",
        "\n",
        "        # image= self.transform(image)\n",
        "\n",
        "        return image, onehot_label\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "labels = mnist_train.targets.numpy()\n",
        "data = mnist_train.data.numpy()\n",
        "test_data = mnist_test.data.numpy()\n",
        "test_labels =  mnist_test.targets.numpy()\n",
        "class_ratios = {0:0, 1:0, 2:0, 3:0, 4:0.005, 5:0, 6:0, 7:0, 8:1, 9:0}\n",
        "noise_ratios = {0:0, 1:0, 2:0, 3:0, 4:0.1, 5:0, 6:0, 7:0, 8:0.1, 9:0}  # noise ratio should be < 1 for each class. If no noise 0\n",
        "\n",
        "class_ratios_test = {0:0, 1:0, 2:0, 3:0, 4:1, 5:0, 6:0, 7:0, 8:1, 9:0}\n",
        "noise_ratios_test = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}  # noise ratio should be < 1 for each class. If no noise 0\n",
        "train_loader = DataLoader(CustomDataset(data, labels, class_ratios,noise_ratios), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(CustomDataset(test_data, test_labels, class_ratios_test,noise_ratios_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "val_loader = DataLoader(CustomDataset(test_data, test_labels, class_ratios_test,noise_ratios_test), batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "aeS9vjhDTWGk",
        "outputId": "857786cb-d43d-4654-d9d7-bce7daf7f6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "tensor(1.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for data, label in train_loader:\n",
        "  break\n",
        "print(data.shape, label.shape)\n",
        "\n",
        "plt.imshow(data[1,0])\n",
        "plt.colorbar()\n",
        "print(label[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pZNw1WdPur4",
        "outputId": "cc878dd9-7fe6-495e-ce2b-00ccb969a245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28])\n",
            "torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "# Collect 100 samples of digit 4 and 8 for validation data\n",
        "X_validation = []\n",
        "y_validation = []\n",
        "\n",
        "counter_4 = 0\n",
        "counter_8 = 0\n",
        "\n",
        "for sample in val_loader:\n",
        "    X_validation.append(sample[0])\n",
        "    y_validation.append(sample[1])\n",
        "\n",
        "X_validation = torch.vstack(X_validation)[:100]\n",
        "y_validation = torch.hstack(y_validation)[:100]\n",
        "print(X_validation.shape)\n",
        "print(y_validation.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MTuD04CVyY2H"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_out):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, n_out)\n",
        "\n",
        "        #max pooling layers\n",
        "        self.maxpool= nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(-1, 128 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x).squeeze()\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "WS9Lw2nHyslP"
      },
      "outputs": [],
      "source": [
        "class trainer():\n",
        "    def __init__(self, model, train_dataloader, test_dataloader, X_validation, y_validation, device):\n",
        "        self.device= device\n",
        "        self.model= model.to(device)\n",
        "        self.train_dataloader= train_dataloader\n",
        "        self.test_dataloader= test_dataloader\n",
        "        self.X_val= X_validation\n",
        "        self.y_val= y_validation\n",
        "\n",
        "\n",
        "    def train_normal(self, epochs):\n",
        "      '''trains the model using traditional approach'''\n",
        "        # criterion= torch.nn.CrossEntropyLoss()\n",
        "        criterion= torch.nn.BCEWithLogitsLoss().to(device)\n",
        "        optimizer= torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        running_loss_per_epoch=[]\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            total_num=0\n",
        "            running_loss= 0\n",
        "            train_acc=0\n",
        "            running_loss_per_batch= []\n",
        "            for i, data in enumerate(self.train_dataloader):\n",
        "                images, labels= data\n",
        "                images= images.to(self.device)  #using cuda\n",
        "                # labels= labels.type(torch.LongTensor).to(self.device) #for softmax\n",
        "                labels= labels.to(self.device)\n",
        "\n",
        "                predicted_logits= self.model(images)\n",
        "                # predicted_probs = F.softmax(predicted_logits, dim=1) #applying softmax along dimension 1\n",
        "                pred_labels= (F.sigmoid(predicted_logits)>0.5).int()\n",
        "                loss= criterion(predicted_logits, labels.type_as(predicted_logits))\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                train_acc += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "                running_loss_per_batch.append(loss.item())\n",
        "                total_num+= len(images)\n",
        "\n",
        "            running_loss_per_epoch.append(np.mean(running_loss_per_batch)) #tracking loss per epoch\n",
        "            print(\"[epoch: %d] loss: %.3f    train accuracy: %.3f\" \\\n",
        "                    % (epoch + 1,  running_loss_per_epoch[-1], (train_acc/total_num)*100))\n",
        "            self.test()\n",
        "\n",
        "        return running_loss_per_epoch\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "        criterion= torch.nn.BCEWithLogitsLoss().to(device)\n",
        "        self.model.eval()  #setting the model in evaluation mode\n",
        "        val_stat={}\n",
        "        all_accuracy=[]\n",
        "        all_loss=[]\n",
        "        all_predictions=[]\n",
        "        all_labels=[]\n",
        "        total_num=0\n",
        "        with torch.no_grad():\n",
        "            running_loss_per_batch=[]\n",
        "            for images, labels in self.test_dataloader:\n",
        "                images, labels= images.to(device), labels.to(device)\n",
        "                pred_logits = self.model(images).float()\n",
        "                labels_tensor = labels.clone().detach()\n",
        "                # predicted_probs= F.softmax(labels_pred, dim=1)\n",
        "                pred_labels= (F.sigmoid(pred_logits)>0.5).int()\n",
        "                loss=criterion(pred_logits, labels_tensor.type_as(pred_logits))\n",
        "                # accuracy=torch.sum((labels_pred.argmax(dim=1) == labels_tensor).float())\n",
        "                accuracy= torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "                running_loss_per_batch.append(loss.item())    #tracking the loss, accuracy, predicted labels, and true labels\n",
        "                all_accuracy.append(accuracy)\n",
        "                all_predictions.append(pred_labels)\n",
        "                all_labels.append(labels)\n",
        "                total_num+=len(images)\n",
        "\n",
        "        val_stat['loss'] = np.mean(running_loss_per_batch)\n",
        "        val_stat['accuracy']=sum(all_accuracy)/total_num\n",
        "        val_stat['prediction']=torch.cat(all_predictions, dim=0)\n",
        "        val_stat['labels']=torch.cat(all_labels, dim=0)\n",
        "        print(f\"Test/Validation result: total sample: {total_num}, Avg loss: {val_stat['loss']:.3f}, Acc: {100*val_stat['accuracy']:.3f}%\")\n",
        "        return val_stat #returning the tracked values in the form of a dictionary\n",
        "\n",
        "\n",
        "\n",
        "    def train_reweighted(self, epochs):\n",
        "        '''trains the model using reweighted sampling approach'''\n",
        "        criterion = torch.nn.BCEWithLogitsLoss().to(self.device)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "        running_loss_per_epoch = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_acc = 0\n",
        "            total_num = 0\n",
        "            running_loss = 0\n",
        "            running_loss_per_batch = []\n",
        "\n",
        "            for i, data in enumerate(self.train_dataloader):\n",
        "                images, labels = data\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                # Inner loop for reweighted training\n",
        "                with metaloop(self.model, optimizer) as (inner_model, inner_optimizer):\n",
        "                    inner_train_outputs = inner_model(images)\n",
        "                    cost = criterion(inner_train_outputs, labels.type_as(inner_train_outputs))\n",
        "\n",
        "                    eps = torch.zeros(cost.size(), requires_grad=True, device=self.device)\n",
        "                    inner_trainloss = torch.sum(eps * cost)\n",
        "                    inner_optimizer.step(inner_trainloss)\n",
        "\n",
        "                    val_loss, eps_grads = self._compute_val_loss_and_gradients(inner_model, eps)\n",
        "\n",
        "                # Compute weights for reweighting based on validation gradients\n",
        "                w_tilde = torch.clamp(-eps_grads, min=0)\n",
        "                norm = torch.sum(w_tilde)\n",
        "                w = w_tilde / norm if norm != 0 else w_tilde\n",
        "\n",
        "                # Perform standard training step using reweighted loss\n",
        "                predicted_logits = self.model(images)\n",
        "                pred_labels = (F.sigmoid(predicted_logits) > 0.5).int()\n",
        "                criterion.reduction= 'none'\n",
        "                loss = criterion(predicted_logits, labels.type_as(predicted_logits))\n",
        "                loss = torch.sum(w * loss)\n",
        "\n",
        "                # Update variables\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                train_acc += torch.sum(torch.eq(pred_labels, labels)).item()\n",
        "                running_loss_per_batch.append(loss.item())\n",
        "                total_num += len(images)\n",
        "\n",
        "            running_loss_per_epoch.append(np.mean(running_loss_per_batch))\n",
        "            print(\"[epoch: %d] loss: %.3f    train accuracy: %.3f\" % (epoch + 1, running_loss_per_epoch[-1], (train_acc / total_num) * 100))\n",
        "            self.test()\n",
        "\n",
        "        return running_loss_per_epoch\n",
        "\n",
        "\n",
        "\n",
        "    def _compute_val_loss_and_gradients(self, model, eps):\n",
        "        '''computes validation loss and gradients for reweighting'''\n",
        "        criterion = torch.nn.BCEWithLogitsLoss(reduction= 'mean').to(self.device)\n",
        "        val_loss = 0\n",
        "        # val_images, val_labels =  next(self.val_dataloader)\n",
        "        val_images, val_labels = self.X_val.to(device=self.device), self.y_val.to(device=self.device)\n",
        "        val_pred_logits = model(val_images)\n",
        "        loss = criterion(val_pred_logits, val_labels.type_as(val_pred_logits))\n",
        "        eps_grads= (torch.autograd.grad(loss, eps, allow_unused=True)[0].detach())\n",
        "        return val_loss, eps_grads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePMJeSa1yvz3",
        "outputId": "c3363748-85d9-48e5-db7b-2bd4b3fa6600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch: 1] loss: 0.694    train accuracy: 48.622\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 2] loss: 0.693    train accuracy: 48.724\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 3] loss: 0.693    train accuracy: 49.473\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 4] loss: 0.693    train accuracy: 49.575\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 5] loss: 0.693    train accuracy: 48.724\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 6] loss: 0.693    train accuracy: 49.779\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 7] loss: 0.693    train accuracy: 50.153\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 8] loss: 0.693    train accuracy: 49.881\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 9] loss: 0.693    train accuracy: 49.405\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 10] loss: 0.693    train accuracy: 49.643\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 11] loss: 0.693    train accuracy: 49.949\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 12] loss: 0.693    train accuracy: 49.065\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 13] loss: 0.693    train accuracy: 49.813\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 14] loss: 0.693    train accuracy: 49.677\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 15] loss: 0.693    train accuracy: 49.609\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 16] loss: 0.693    train accuracy: 49.439\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 17] loss: 0.693    train accuracy: 49.643\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 18] loss: 0.693    train accuracy: 50.017\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 19] loss: 0.693    train accuracy: 49.473\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n",
            "[epoch: 20] loss: 0.693    train accuracy: 50.153\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 49.796%\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model using traditional method\n",
        "model = SimpleCNN(n_out=1)\n",
        "my_trainer_normal= trainer(model, train_loader, test_loader, X_validation, y_validation, device)\n",
        "normal_losses=my_trainer_normal.train_normal(epochs= 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkseamgWzMdW",
        "outputId": "8027a733-9052-430c-d683-dad9347f3faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch: 1] loss: 0.682    train accuracy: 49.847\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.696, Acc: 50.204%\n",
            "[epoch: 2] loss: 0.688    train accuracy: 49.847\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.693, Acc: 50.204%\n",
            "[epoch: 3] loss: 0.600    train accuracy: 49.949\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.208, Acc: 93.916%\n",
            "[epoch: 4] loss: 0.428    train accuracy: 50.918\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.179, Acc: 97.188%\n",
            "[epoch: 5] loss: 0.345    train accuracy: 50.748\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.127, Acc: 97.597%\n",
            "[epoch: 6] loss: 0.290    train accuracy: 50.731\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.088, Acc: 97.904%\n",
            "[epoch: 7] loss: 0.300    train accuracy: 50.731\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.061, Acc: 97.853%\n",
            "[epoch: 8] loss: 0.318    train accuracy: 50.510\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.064, Acc: 97.955%\n",
            "[epoch: 9] loss: 0.366    train accuracy: 50.714\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.062, Acc: 97.955%\n",
            "[epoch: 10] loss: 0.314    train accuracy: 50.748\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.131, Acc: 97.137%\n",
            "[epoch: 11] loss: 0.291    train accuracy: 50.663\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.116, Acc: 97.853%\n",
            "[epoch: 12] loss: 0.262    train accuracy: 50.918\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.059, Acc: 98.108%\n",
            "[epoch: 13] loss: 0.326    train accuracy: 50.799\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.070, Acc: 97.699%\n",
            "[epoch: 14] loss: 0.336    train accuracy: 50.918\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.055, Acc: 98.466%\n",
            "[epoch: 15] loss: 0.292    train accuracy: 51.156\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.082, Acc: 97.495%\n",
            "[epoch: 16] loss: 0.338    train accuracy: 50.969\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.064, Acc: 97.648%\n",
            "[epoch: 17] loss: 0.304    train accuracy: 51.088\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.062, Acc: 98.108%\n",
            "[epoch: 18] loss: 0.301    train accuracy: 51.071\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.059, Acc: 98.517%\n",
            "[epoch: 19] loss: 0.272    train accuracy: 50.969\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.053, Acc: 98.466%\n",
            "[epoch: 20] loss: 0.295    train accuracy: 51.071\n",
            "Test/Validation result: total sample: 1956, Avg loss: 0.053, Acc: 98.517%\n"
          ]
        }
      ],
      "source": [
        "# Instantiate and train model using proposed method\n",
        "model2= SimpleCNN(n_out=1)\n",
        "my_trainer2= trainer(model2, train_loader, test_loader, X_validation, y_validation, device)\n",
        "reweighted=my_trainer2.train_reweighted(epochs= 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wDZ2KWXHSf9G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}