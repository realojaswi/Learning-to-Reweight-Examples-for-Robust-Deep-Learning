# Learning-to-Reweight-Examples-for-Robust-Deep-Learning

The plots Comparison1-Comparison4.png display the effectiveness of the implemented technique. If we look at Comparison2, the ideal case when there is no noise and dataset is balanced, both the normal model and the adopted approach produce almost 100% accuracy on test dataset. But once we move away from the ideal scenario, let's say in comparison3, when there is a data imbalance in the ratio of 5:1 but still no noise, the test accuracy for the normal approach starts to falter whereas for the adopted approach, it is still stable at around 99% accuracy. Then, in comparison4, the noise is increased to 0.25, which produces similar result between two approaches. Now to further test the approach, for comparison5, the data imbalance is increased to 20:1, and the noise is 0.1. In this case, the adopted approach still achieves near 100% accuracy whereas the normal approach understandably lingers around 50%. Finally, we push our method to the limits in comparison6 and comparison7. In comparison6, the data imbalance is 200:1 and the noise is 0.1 whereas in comparison7, data imbalance is 200:1 and the noise is 0.25. Still, the adopted method is able to have almost 96% accuracy compared to 50% for the normal method.
